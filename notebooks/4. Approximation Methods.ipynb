{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation Methods\n",
    "\n",
    "> “An approximate answer to the right problem is worth a good deal more than\n",
    "an exact answer to an approximate problem.” -- John Tukey\n",
    "\n",
    "Markov chain Monte Carlo (MCMC) is the *de facto* standard for the estimation of Bayesian models. It is an important and useful approach because it is asymptotically exact and can be implemented readily in software and applied to a wide range of probabilistic models. The main drawback of MCMC is its **computational expense**, as it requires repeated calculation of likelihoods and other quantities at every iteration of the algorithm. These calculations typically involve all of the data specified in the model, and hence do not scale well with the size of the dataset being used to fit the model.\n",
    "\n",
    "An alternative to this employs one of several *approximation* methods. By an approximation, we are here referring to methods that do not exactly calculate or sample from the full posterior distribution specified by the model, but rather, either returns one or more moments of the posterior or use an alternative functional form in place of the true posterior distribution. We will outline two of these methods that are available in PyMC3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum a posteriori (MAP) estimation\n",
    "\n",
    "The most straightforward way for obtaining estimates from a Bayesian model is to find the maximum *a posteriori* estimate of the model parameters. This simply involves applying a numerical optimization algorithm to the model, several of which are available in the SciPy package for Python. Since the marginal likelihood is a constant with respect to the parameters, the estimates of the parameters derived from a non-normalized model will be the same as those from a normalized model. \n",
    "\n",
    "$$\\hat{\\theta}_{MAP}(y) = \\text{argmax}_{\\theta} \\frac{Pr(y|\\theta)Pr(\\theta)}{\\int Pr(y|\\theta)Pr(\\theta) d\\theta} = \\text{argmax}_{\\theta} Pr(y|\\theta)Pr(\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use MAP to obtain estimates for the survival model that we introduced previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../data/melanoma_data.py\n",
    "from numpy import reshape, sum\n",
    "\n",
    "melanoma_data = reshape([1.57808, 0.00000, 2, 1.27, 35.9945, 1, 1.48219,\n",
    "     0.00000, 2, 0.76, 41.9014, 1, 0.0, 7.33425, 1, 35.00, 70.2164, 2, 2.23288,\n",
    "     0.00000, 1, 1.70, 33.7096, 1, 0.0, 9.38356, 2, 1.00, 47.9726, 1, 3.27671,\n",
    "     0.00000, 1, 11.00, 31.8219, 2, 0.0, 9.64384, 1, 6.50, 32.9479, 1, 1.66575,\n",
    "     0.00000, 2, 3.62, 35.9205, 1, 0.94247, 0.00000, 1, 8.50, 40.5068, 2,\n",
    "     1.68767, 0.00000, 2, 4.20, 57.0384, 1, 2.34247, 0.00000, 2, 5.00, 62.0630, 1,\n",
    "     0.89863, 0.00000, 1, 2.25, 56.5342, 1, 0.0, 9.03288, 2, 2.30, 22.9945, 2,\n",
    "     0.0, 9.63014, 2, 10.00, 18.4712, 1, 0.52603, 0.00000, 1, 3.35, 41.2521, 1,\n",
    "     1.82192, 0.00000, 2, 3.80, 29.5178, 1, 0.93425, 0.00000, 1, 0.75, 59.0493, 2,\n",
    "     0.0, 8.98630, 2, 0.50, 32.2877, 1, 3.35068, 0.00000, 1, 0.46, 26.4822, 1,\n",
    "     8.67397, 0.00000, 1, 2.55, 55.0411, 1, 0.41096, 0.00000, 2, 1.95, 55.1233, 2,\n",
    "     2.78630, 0.00000, 1, 2.50, 22.4055, 2, 2.56438, 0.00000, 1, 2.10, 50.8466, 1,\n",
    "     0.0, 8.75342, 2, 9.00, 56.0274, 1, 0.56986, 0.00000, 2, 5.00, 55.4767, 1,\n",
    "     0.0, 8.40000, 1, 0.55, 41.2411, 1, 0.0, 7.25205, 1, 12.50, 32.7425, 1,\n",
    "     4.38630, 0.00000, 2, 1.16, 45.3479, 1, 0.0, 8.36712, 2, 4.25, 42.8438, 2,\n",
    "     0.0, 8.99178, 2, 15.00, 51.1068, 1, 0.86575, 0.00000, 2, 0.72, 30.1808, 1,\n",
    "     0.0, 4.76986, 1, 1.50, 58.7014, 2, 1.15616, 0.00000, 2, 6.50, 51.5397, 1,\n",
    "     0.0, 7.28767, 1, 2.75, 27.1973, 1, 3.13151, 0.00000, 1, 3.83, 67.6740, 1,\n",
    "     0.0, 8.55068, 2, 1.80, 64.4274, 2, 0.0, 8.45753, 2, 4.75, 35.4411, 1,\n",
    "     4.59452, 0.00000, 1, 5.80, 35.9452, 1, 2.88219, 0.00000, 2, 0.51, 48.1370, 1,\n",
    "     0.89589, 0.00000, 1, 3.25, 58.6082, 1, 1.76164, 0.00000, 2, 0.90, 40.0137, 2,\n",
    "     0.0, 7.81370, 1, 3.45, 26.0055, 1, 0.0, 8.33425, 2, 1.38, 36.9616, 1,\n",
    "     2.62192, 0.00000, 1, 5.28, 25.9068, 2, 0.16164, 0.00000, 2, 3.00, 63.8055, 1,\n",
    "     0.0, 8.24658, 1, 2.20, 29.6986, 2, 1.52603, 0.00000, 1, 7.00, 61.6384, 1,\n",
    "     5.30959, 0.00000, 1, 4.00, 49.9918, 1, 0.87123, 0.00000, 2, 2.36, 37.1068, 1,\n",
    "     0.41644, 0.00000, 1, 1.06, 53.4658, 2, 4.24110, 0.00000, 1, 6.50, 57.7425, 2,\n",
    "     0.13699, 0.00000, 1, 10.00, 29.1479, 1, 7.07671, 0.00000, 2, 1.20, 59.2466,\n",
    "     1, 0.13151, 0.00000, 2, 15.00, 61.3507, 2, 0.0, 8.02740, 1, 0.49, 33.9205,\n",
    "     2, 0.0, 6.16164, 2, 1.60, 43.1918, 1, 1.29863, 0.00000, 2, 11.50, 34.1890,\n",
    "     2, 1.29041, 0.00000, 2, 1.90, 58.3808, 2, 0.0, 7.99726, 1, 4.80, 21.9479,\n",
    "     2, 0.0, 8.34795, 1, 0.55, 35.1151, 1, 0.0, 7.30137, 2, 6.50, 31.6493, 1,\n",
    "     2.32877, 0.00000, 2, 12.00, 56.1890, 1, 0.56438, 0.00000, 1, 7.00, 60.7123,\n",
    "     1, 5.62740, 0.00000, 2, 6.50, 58.8329, 2, 1.23014, 0.00000, 1, 1.60,\n",
    "     44.4849, 2, 0.0, 7.94521, 1, 1.15, 51.1315, 2, 5.06301, 0.00000, 1, 2.65,\n",
    "     34.2164, 1, 3.27671, 0.00000, 2, 2.00, 35.2301, 1, 0.0, 0.60822, 2, 2.50,\n",
    "     32.7425, 2, 0.65753, 0.00000, 1, 4.38, 38.0986, 2, 0.84110, 0.00000, 2,\n",
    "     2.93, 45.7699, 1, 0.0, 8.40000, 2, 3.00, 44.2000, 1, 0.18356, 0.00000, 1,\n",
    "     2.50, 71.3260, 1, 2.62466, 0.00000, 2, 2.30, 59.0795, 1, 0.0, 7.96438, 2,\n",
    "     2.00, 35.3836, 2, 0.0, 7.77808, 1, 0.75, 58.0438, 2, 0.22192, 0.00000, 1,\n",
    "     5.00, 43.2164, 1, 2.33973, 0.00000, 1, 10.00, 60.4932, 1, 0.52329, 0.00000,\n",
    "     1, 0.87, 32.4795, 2, 0.0, 8.04110, 2, 1.33, 60.2986, 1, 0.0, 7.83288, 1,\n",
    "     5.60, 47.1342, 1, 0.64110, 0.00000, 1, 2.55, 42.3233, 1, 0.38356, 0.00000,\n",
    "     1, 6.50, 54.4164, 1, 0.0, 7.82192, 2, 1.20, 51.4219, 1, 0.51781, 0.00000,\n",
    "     2, 3.00, 46.5973, 1, 0.0, 8.09863, 2, 2.55, 58.3562, 1, 0.0, 8.16712, 2,\n",
    "     1.61, 25.6712, 2, 4.42740, 0.00000, 1, 1.40, 29.1726, 1, 0.88493, 0.00000,\n",
    "     1, 2.25, 18.6795, 1, 2.78356, 0.00000, 1, 4.50, 60.9671, 2, 2.64658,\n",
    "     0.00000, 2, 0.81, 63.8849, 2, 0.0, 8.21370, 2, 1.30, 37.9808, 2, 0.0,\n",
    "     7.41918, 2, 3.20, 32.3507, 2, 0.99726, 0.00000, 1, 1.29, 42.9589, 1,\n",
    "     5.88493, 0.00000, 2, 4.40, 40.9562, 1, 0.41644, 0.00000, 1, 6.00, 61.9753, 1,\n",
    "     3.53699, 0.00000, 1, 3.93, 55.3315, 2, 0.0, 7.56164, 1, 0.60, 36.0767, 1,\n",
    "     0.0, 7.53151, 1, 0.75, 50.6795, 1, 0.27671, 0.00000, 1, 0.73, 66.6986, 1,\n",
    "     0.76986, 0.00000, 2, 0.20, 29.3479, 2, 0.0, 7.62192, 2, 3.88, 33.1863, 1,\n",
    "     0.0, 7.79726, 1, 2.48, 48.6356, 2, 0.64110, 0.00000, 1, 2.50, 29.4877, 1,\n",
    "     1.14521, 0.00000, 2, 10.00, 42.6685, 1, 2.01644, 0.00000, 1, 16.00, 24.4055,\n",
    "     2, 2.84384, 0.00000, 1, 4.00, 40.3890, 1, 0.0, 7.00000, 2, 1.35, 45.4192,\n",
    "     1, 1.27397, 0.00000, 2, 3.00, 65.3945, 1, 0.0, 7.09589, 1, 10.72, 47.5753,\n",
    "     2, 2.04110, 0.00000, 1, 1.50, 58.4438, 2, 0.83562, 0.00000, 1, 3.50,\n",
    "     59.2767, 2, 0.92329, 0.00000, 1, 1.10, 30.2630, 2, 0.07397, 0.00000, 1,\n",
    "     1.00, 40.7370, 1, 0.0, 7.30685, 2, 5.10, 44.7452, 1, 2.07671, 0.00000, 2,\n",
    "     0.50, 67.8329, 1, 0.0, 7.70959, 2, 4.03, 27.7452, 1, 0.0, 6.15890, 1,\n",
    "     1.80, 25.9260, 2, 0.0, 6.89315, 2, 3.50, 31.2740, 1, 3.30685, 0.00000, 1,\n",
    "     1.15, 58.8822, 2, 0.36164, 0.00000, 1, 1.75, 57.0575, 1, 1.97808, 0.00000,\n",
    "     2, 2.50, 59.8137, 1, 1.23836, 0.00000, 2, 2.10, 77.5151, 1, 0.10685,\n",
    "     0.00000, 1, 1.35, 43.4219, 1, 0.0, 7.63836, 1, 4.50, 52.2082, 1, 2.06301,\n",
    "     0.00000, 1, 0.50, 36.3205, 2, 0.0, 7.42466, 2, 2.30, 25.9781, 1, 0.50959,\n",
    "     0.00000, 1, 4.00, 49.4411, 1, 0.65753, 0.00000, 1, 5.40, 57.9589, 1, 0.0,\n",
    "     6.93151, 1, 6.00, 65.5644, 1, 0.0, 7.23288, 2, 5.10, 72.3425, 1, 6.01096,\n",
    "     0.00000, 1, 4.50, 68.8548, 1, 0.33699, 0.00000, 1, 1.45, 50.4438, 2, 0.0,\n",
    "     6.47123, 2, 3.38, 48.2877, 1, 0.94795, 0.00000, 1, 3.00, 46.9479, 2,\n",
    "     2.91781, 0.00000, 2, 1.20, 33.6000, 2, 1.59726, 0.00000, 2, 7.30, 51.1644, 2,\n",
    "     0.84932, 0.00000, 2, 1.67, 47.7836, 1, 1.38356, 0.00000, 1, 4.00, 53.8795, 2,\n",
    "     3.81644, 0.00000, 2, 2.10, 38.7068, 2, 0.0, 7.06849, 1, 10.00, 69.3205, 2,\n",
    "     0.0, 7.04110, 2, 3.50, 66.0219, 1, 1.00274, 0.00000, 2, 1.10, 36.0329, 2,\n",
    "     0.0, 6.34795, 2, 0.40, 63.4603, 1, 1.18082, 0.00000, 1, 0.70, 48.8986, 2,\n",
    "     0.97534, 0.00000, 1, 5.00, 45.0575, 1, 2.16712, 0.00000, 1, 0.85, 57.6712, 2,\n",
    "     0.0, 6.85479, 1, 4.80, 45.2000, 1, 1.38356, 0.00000, 1, 1.20, 49.0438, 1,\n",
    "     1.71507, 0.00000, 2, 1.30, 51.4630, 1, 0.79452, 0.00000, 2, 5.80, 34.5479, 1,\n",
    "     0.0, 6.86301, 2, 6.00, 47.6438, 2, 0.0, 6.50411, 1, 3.00, 38.7233, 2,\n",
    "     0.42466, 0.00000, 2, 1.88, 54.0658, 1, 0.98630, 0.00000, 1, 2.60, 45.7397, 1,\n",
    "     0.0, 6.13699, 2, 2.70, 47.2822, 2, 3.80000, 0.00000, 2, 6.00, 62.6411, 1,\n",
    "     0.0, 6.48493, 1, 4.00, 62.0192, 2, 0.0, 6.96438, 2, 1.71, 41.0904, 2, 0.0,\n",
    "     6.78082, 2, 1.60, 50.2712, 2, 0.56164, 0.00000, 2, 1.50, 49.5288, 2,\n",
    "     2.67123, 0.00000, 1, 3.00, 70.8192, 1, 1.56712, 0.00000, 2, 0.90, 59.0712, 1,\n",
    "     2.07397, 0.00000, 2, 4.00, 53.9041, 1, 0.33973, 0.00000, 1, 2.80, 44.7342, 1,\n",
    "     3.37808, 0.00000, 2, 0.80, 22.1397, 1, 3.15068, 0.00000, 1, 0.70, 72.8575, 1,\n",
    "     0.0, 6.81096, 2, 0.90, 61.4521, 1, 3.20822, 0.00000, 2, 12.00, 61.2904, 1,\n",
    "     0.62740, 0.00000, 1, 5.78, 34.7507, 1, 1.64384, 0.00000, 1, 0.60, 67.4164, 2,\n",
    "     1.40822, 0.00000, 1, 12.00, 53.2493, 1, 0.0, 6.06575, 1, 4.00, 49.0082, 1,\n",
    "     1.66301, 0.00000, 2, 0.45, 56.7699, 1, 1.36986, 0.00000, 2, 1.30, 34.0247, 2,\n",
    "     5.46849, 0.00000, 1, 0.81, 34.3014, 2, 0.42740, 0.00000, 1, 3.20, 45.0712, 2,\n",
    "     1.13973, 0.00000, 2, 4.00, 54.7671, 2, 1.73699, 0.00000, 2, 4.77, 42.8548, 2,\n",
    "     0.0, 5.54521, 2, 2.20, 36.6301, 2, 0.85205, 0.00000, 1, 3.00, 43.2466, 1,\n",
    "     0.43014, 0.00000, 1, 3.00, 53.3562, 1, 1.20822, 0.00000, 2, 0.80, 35.3534, 1,\n",
    "     4.36164, 0.00000, 1, 4.00, 36.5233, 1, 0.52877, 0.00000, 2, 5.00, 52.7863, 1,\n",
    "     0.0, 6.51507, 1, 2.00, 24.4329, 2, 2.89863, 0.00000, 2, 3.85, 58.7178, 1,\n",
    "     0.0, 6.20274, 2, 0.76, 45.5479, 1, 1.21644, 0.00000, 2, 0.75, 43.3014, 2,\n",
    "     0.0, 6.00000, 2, 6.50, 51.4055, 2, 0.0, 6.25479, 1, 0.85, 38.9671, 2, 0.0,\n",
    "     6.49863, 1, 4.30, 68.2658, 1, 1.13699, 0.00000, 2, 2.10, 59.4493, 2,\n",
    "     1.69589, 0.00000, 1, 1.50, 30.0192, 1, 0.0, 6.41096, 2, 2.00, 22.1562, 2,\n",
    "     0.0, 6.02192, 1, 11.00, 54.7671, 1, 3.04932, 0.00000, 2, 4.88, 45.0384, 1,\n",
    "     0.0, 5.62740, 2, 5.20, 39.7589, 1, 0.72603, 0.00000, 1, 3.04, 41.3808, 1,\n",
    "     0.73425, 0.00000, 2, 8.00, 34.9671, 1, 1.47945, 0.00000, 2, 1.60, 46.3479, 1,\n",
    "     0.37808, 0.00000, 2, 1.10, 29.9233, 2, 0.0, 5.75890, 2, 3.00, 32.8740, 1,\n",
    "     1.48219, 0.00000, 2, 10.00, 39.5397, 2, 0.0, 5.88493, 1, 1.95, 55.4822, 1,\n",
    "     0.0, 1.80274, 1, 2.00, 32.3562, 1, 1.40548, 0.00000, 2, 3.70, 41.8027, 2,\n",
    "     0.0, 4.74795, 1, 2.90, 35.3452, 2, 0.0, 5.24658, 1, 1.80, 50.4795, 1,\n",
    "     0.29041, 0.00000, 1, 6.00, 61.3507, 2, 0.0, 5.83836, 1, 1.50, 67.3562, 1,\n",
    "     0.0, 5.32055, 2, 1.75, 53.8548, 2, 5.16712, 0.00000, 2, 5.00, 78.7315, 2,\n",
    "     0.0, 5.59178, 2, 0.63, 62.7233, 1, 0.0, 5.77808, 1, 1.15, 65.1507, 1,\n",
    "     0.53425, 0.00000, 2, 1.50, 34.8274, 1, 0.0, 2.22466, 1, 0.98, 33.8466, 2,\n",
    "     3.59726, 0.00000, 1, 5.00, 67.8822, 1, 0.0, 5.32329, 1, 5.50, 66.0712, 2,\n",
    "     1.78630, 0.00000, 2, 1.00, 55.0658, 2, 0.70411, 0.00000, 2, 10.00, 50.5123,\n",
    "     1, 0.0, 4.94795, 2, 5.00, 42.4055, 2, 0.0, 5.45479, 2, 3.75, 58.1068, 2,\n",
    "     4.32877, 0.00000, 1, 10.00, 26.0137, 1, 1.16164, 0.00000, 2, 3.00, 54.4685,\n",
    "     1, 0.0, 5.20274, 2, 8.00, 54.0630, 2, 0.0, 4.40822, 1, 1.64, 34.5589, 1,\n",
    "     1.41096, 0.00000, 1, 4.95, 58.5068, 1, 0.0, 4.92877, 2, 1.45, 63.9370, 1,\n",
    "     0.0, 5.42192, 2, 12.00, 49.8274, 2, 0.98904, 0.00000, 1, 2.05, 50.5562, 1,\n",
    "     0.36438, 0.00000, 1, 3.60, 40.4795, 2, 0.0, 4.38082, 1, 8.30, 61.7479, 2,\n",
    "     0.77260, 0.00000, 2, 0.45, 41.6712, 1, 4.90959, 0.00000, 2, 3.00, 25.5096, 1,\n",
    "     1.26849, 0.00000, 1, 4.40, 61.2000, 1, 0.58082, 0.00000, 2, 1.10, 53.1260, 1,\n",
    "     0.0, 4.95616, 1, 1.05, 40.4658, 1, 0.0, 5.12329, 1, 1.71, 60.3068, 1, 0.0,\n",
    "     4.74795, 1, 6.30, 48.7425, 2, 0.0, 4.90685, 2, 0.50, 46.7562, 2, 1.41918,\n",
    "     0.00000, 1, 5.10, 34.8932, 2, 0.44110, 0.00000, 1, 6.00, 33.3096, 1, 0.0,\n",
    "     4.29863, 2, 1.50, 35.7589, 1, 0.0, 4.63836, 2, 0.36, 49.8575, 1, 0.0,\n",
    "     4.81370, 1, 3.00, 57.3726, 2, 4.50137, 0.00000, 2, 1.24, 29.7726, 2,\n",
    "     3.92329, 0.00000, 2, 0.70, 51.8822, 2, 0.0, 4.86027, 2, 0.80, 65.3123, 2,\n",
    "     0.52603, 0.00000, 1, 1.00, 52.0658, 2, 2.10685, 0.00000, 2, 3.38, 60.9534, 2,\n",
    "     0.0, 4.24384, 1, 1.52, 32.6055, 2, 3.39178, 0.00000, 1, 2.20, 51.5123, 2,\n",
    "     0.0, 4.36164, 2, 2.10, 48.6548, 1, 0.0, 4.81918, 2, 1.40, 43.8438, 2],\n",
    "(255, 6))\n",
    "\n",
    "# Censoring indicator\n",
    "censored = (melanoma_data[:, 0] == 0).astype(int)\n",
    "# Time\n",
    "t = sum(melanoma_data[:, 0:2], 1)\n",
    "# Treatment\n",
    "treat = melanoma_data[:, 2].astype(int) - 1\n",
    "# Breslow scale\n",
    "breslow = melanoma_data[:, 3]\n",
    "# Age and sex\n",
    "age = melanoma_data[:, 4]\n",
    "sex = melanoma_data[:, 5].astype(int) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3 import Normal, Model, DensityDist, sample, log, exp\n",
    "\n",
    "with Model() as melanoma_survival:\n",
    "\n",
    "    # Convert censoring indicators to indicators for failure event\n",
    "    failure = (censored==0).astype(int)\n",
    "\n",
    "    # Parameters (intercept and treatment effect) for survival rate\n",
    "    beta = Normal('beta', mu=0.0, sd=1e5, shape=2)\n",
    "\n",
    "    # Survival rates, as a function of treatment\n",
    "    lam = exp(beta[0] + beta[1]*treat)\n",
    "    \n",
    "    # Survival likelihood, accounting for censoring\n",
    "    def logp(failure, value):\n",
    "        return (failure * log(lam) - lam * value).sum()\n",
    "\n",
    "    x = DensityDist('x', logp, observed={'failure':failure, 'value':t})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAP estimate can be obtained in PyMC3 via the `find_MAP` function. As with `sample`, we run `find_MAP` inside a model context, or pass the model explicitly to the function as the `model` parameter.\n",
    "\n",
    "Starting values can be optionally passed as a `dict` to the `start` parameter. By default, `fmin_MAP` uses SciPy's `fmin_bfgs` function to find the maximum, which is an implementation of the [Broyden–Fletcher–Goldfarb–Shanno algorithm](https://en.wikipedia.org/wiki/Broyden–Fletcher–Goldfarb–Shanno_algorithm). If there are discrete variables in the model, then `fmin_powell` is used, which is SciPy's implementation of [Powell's method](https://en.wikipedia.org/wiki/Powell%27s_method), a more general algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3 import find_MAP\n",
    "\n",
    "with melanoma_survival:\n",
    "    estimates = find_MAP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, the MAP estimates are comparable to those we would have obtained using MCMC sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned NUTS to beta\n",
      " [-----------------100%-----------------] 1000 of 1000 complete in 0.5 sec"
     ]
    }
   ],
   "source": [
    "from pymc3 import sample\n",
    "\n",
    "with melanoma_survival:\n",
    "    trace = sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "beta:\n",
      "\n",
      "  Mean             SD               MC Error         95% HPD interval\n",
      "  -------------------------------------------------------------------\n",
      "  \n",
      "  -1.675           0.158            0.010            [-1.937, -1.479]\n",
      "  -0.271           0.173            0.008            [-0.575, 0.063]\n",
      "\n",
      "  Posterior quantiles:\n",
      "  2.5            25             50             75             97.5\n",
      "  |--------------|==============|==============|--------------|\n",
      "  \n",
      "  -1.917         -1.762         -1.674         -1.598         -1.452\n",
      "  -0.579         -0.399         -0.277         -0.148         0.063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pymc3 import summary\n",
    "\n",
    "summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_MAP` only returns estimates unobserved random variables from the model, and does not include deterministic values. If we wish to evaluate a determinsitic quantity, we can construct a Theano function and pass in the relevant parameter values as arguments.\n",
    "\n",
    "### Exercise: calculating deterministic quantities\n",
    "\n",
    "Create a Theano function to evaluate the deterministic `lam` variable at the MAP estimates for beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import function\n",
    "\n",
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major limitation to using MAP for inference is that there is no associated measure of uncertainty. Hence, `find_MAP` cannot be used for inference. It is useful, however, for getting a sense of typical values the model may take for a particular dataset, and for PyMC3 it is intended to be used to get reasonable starting values for use in MCMC algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference\n",
    "\n",
    "An alternative approach to approximating the posterior disstribution that is difficult to calculate analytically is to perform inference on an appoximation to the true posterior distribution. \n",
    "\n",
    "The idea is to choose a convenient approximating density $q(\\theta, \\phi)$, with vector of corresponding parameters $\\phi$. The goal is to select $\\phi$ such that $q(\\theta, \\phi)$ is as similar as possible to the true posterior. We therefore require a loss function that measures the similarity of $q(\\theta, \\phi)$ to $p(\\theta| y)$.\n",
    "\n",
    "The loss function employed by variational inference is the **Kullback-Leibler distance**:\n",
    "\n",
    "$$\\text{KL}[q(\\theta, \\phi) || p(\\theta| y)] = \\int q(\\theta, \\phi) \\frac{q(\\theta, \\phi)}{p(\\theta| y)} d\\theta$$\n",
    "\n",
    "However, this integral is difficult to work with, so instead a proxy to KL, called the evidence lower bound, is minimized instead:\n",
    "\n",
    "$$ELBO = \\mathbb{E}_{q(\\theta)} [\\log p(y, \\theta)] − \\mathbb{E}_{q(θ)} [\\log q(\\theta, \\phi)]$$\n",
    "\n",
    "The first term of the ELBO expression $\\mathbb{E}_{q(\\theta)} [\\log p(y, \\theta)]$ is the expectation of the log joint density under the approximation, while the second term $\\mathbb{E}_{q(θ)} [\\log q(\\theta, \\phi)]$ is called the *entropy* of the variational approximation.\n",
    "\n",
    "Algorithms for performing variational inference are difficult to construct, and this has limited its adoption for applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation Variational Inference\n",
    "\n",
    "Kucukelbir et al. (2015) devised a method for automating the variational inference approach, by making a flexible choice for the approximating distribution, and transforming the latent variables to an unconstrained coordinate space before fitting the model.\n",
    "\n",
    "ADVI proceeds in three steps:\n",
    "\n",
    "1. Transform the model's latent variables to the real coordinate space\n",
    "2. Specify a normal variational distribution.\n",
    "3. Maximize the variational objective via automatic differentiation and stochastic optimization\n",
    "\n",
    "The ADVI procedure works for differentiable probability models (*i.e.* those comprised of continuous latent variables) only. This is because it requires the calculation of the gradient of the log-joint with respect to the stochastic variables:\n",
    "\n",
    "$$\\nabla_{\\theta} \\log p(y, \\theta)$$\n",
    "\n",
    "The key to making ADVI work is the transformation of constrained parameters to the unconstrained, real coordinate space. This allows us to use a Gaussian distribution as the variational density. As with the classical variational inference algorithm, we impose the mean field assumption, whereby the Gaussian distributions over all the parameters can be fully factorized:\n",
    "\n",
    "$$q(\\zeta, \\phi) = \\prod_{j=1}^J N(\\zeta | \\mu_j, \\sigma_j^2)$$\n",
    "\n",
    "where $\\zeta$ are the parameters after tranformation by $T: \\theta \\rightarrow \\zeta$.\n",
    "\n",
    "The inverse of the transform used (*e.g.* log for positive variables, logit for probabilities) and the associated Jacobian allows for a non-normal variational approximation on the support of the original variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied log-transform to sd and added transformed sd_log to model.\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model: \n",
    "    mu = pm.Normal('mu', mu=0, sd=1, testval=0)\n",
    "    sd = pm.HalfNormal('sd', sd=1)\n",
    "    n = pm.Normal('n', mu=mu, sd=sd, observed=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 [0%]: ELBO = -843.14\n",
      "Iteration 1000 [10%]: Average ELBO = -658.32\n",
      "Iteration 2000 [20%]: Average ELBO = -243.64\n",
      "Iteration 3000 [30%]: Average ELBO = -181.58\n",
      "Iteration 4000 [40%]: Average ELBO = -165.68\n",
      "Iteration 5000 [50%]: Average ELBO = -157.39\n",
      "Iteration 6000 [60%]: Average ELBO = -153.11\n",
      "Iteration 7000 [70%]: Average ELBO = -151.13\n",
      "Iteration 8000 [80%]: Average ELBO = -150.31\n",
      "Iteration 9000 [90%]: Average ELBO = -150.09\n",
      "Finished [100%]: Average ELBO = -150.06\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    \n",
    "    means, sds, elbos = pm.variational.advi(model=model, n=10000, accurate_elbo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': array(0.09900916031993148), 'sd_log': array(0.043599325193635664)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned NUTS to mu\n",
      "Assigned NUTS to sd_log\n",
      " [-----------------100%-----------------] 1000 of 1000 complete in 1.3 sec"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace = pm.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1208e9b00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEKCAYAAAALoA6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12080b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "ax = sns.distplot(trace['mu'], label='NUTS')\n",
    "xlim = ax.get_xlim()\n",
    "x = np.linspace(xlim[0], xlim[1], 100)\n",
    "y = stats.norm(means['mu'], sds['mu']).pdf(x)\n",
    "ax.plot(x, y, label='ADVI')\n",
    "ax.set_title('mu')\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1.\tKucukelbir A, Ranganath R, Gelman A, Blei DM. Automatic Variational Inference in Stan. arXiv. 2015;stat.ML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
